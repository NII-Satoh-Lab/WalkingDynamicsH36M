{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "from skeleton import SoMoFSkeleton\n",
    "\n",
    "from model.utils.plot import get_np_frames_3d_projection\n",
    "from model.utils.image import  save_gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../data/somof_data_3dpw\"\n",
    "dataset_name = \"3dpw\"\n",
    "name_split = \"test\"\n",
    "path_to_submission = \"../output/somof/exp_name/test_num_epoch\"\n",
    "sub_file_name = \"3dpw_predictions.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton = SoMoFSkeleton(num_joints=13, if_consider_hip=True, pose_box_size=1200) # box size is not used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 2, 16, 13, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(dataset_path, f\"{dataset_name}_{name_split}_in.json\"), 'r') as f:\n",
    "    data_in = np.array(json.load(f))\n",
    "    \n",
    "data_in = torch.from_numpy(data_in).view(data_in.shape[0], 2, 16, 13, 3)\n",
    "data_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 2, 14, 13, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(path_to_submission, sub_file_name), 'r') as f:\n",
    "    data_pred = np.array(json.load(f))\n",
    "data_pred = torch.from_numpy(data_pred).view(data_pred.shape[0], 2, 14, 13, 3)\n",
    "data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat([data_in, data_pred], dim=-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visual(data_track, name=\"frames\"):\n",
    "  track= data_track.clone()\n",
    "  track[..., 1] *= -1\n",
    "  frames_in = torch.stack(get_np_frames_3d_projection(track[:16, :, :].numpy()*1000,limbseq=skeleton.limbseq, left_right_limb=skeleton.left_right_limb, \n",
    "                                                    xyz_range=None, center_pose=False, units=\"mm\", \n",
    "                                                  as_tensor=True, orientation_like=\"h36m\", title=\"gt Kpts\"), dim=0)\n",
    "  fake_start = track[0].unsqueeze(0).broadcast_to(track.shape)\n",
    "  frames_pred = torch.stack(get_np_frames_3d_projection(fake_start.numpy()*1000,data_pred=track.numpy()*1000, limbseq=skeleton.limbseq, left_right_limb=skeleton.left_right_limb, \n",
    "                                                    xyz_range=None, center_pose=False, units=\"mm\", \n",
    "                                                  as_tensor=True, orientation_like=\"h36m\", title=\"gt Kpts\"), dim=0)\n",
    "  frames = torch.cat([frames_in, frames_pred[16:]], dim=0)\n",
    "  save_gif(frames, name=os.path.join(path_to_submission, name), fps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = data.view(-1, 30, 13, 3)[0]\n",
    "save_visual(track, name=\"frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose = track - track[..., 0,:].unsqueeze(-2)\n",
    "save_visual(pose, name=\"frames_pose\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3121, -0.7862,  1.0315], dtype=torch.float64) tensor([ 0.5139, -1.0141,  1.2629], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(track[15, 0], track[16, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5819f3b8f5800803f3e1de74b59ba921220bb925d6306341dfc4ace99a37b42c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
