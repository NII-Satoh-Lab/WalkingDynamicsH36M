{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import UserDict\n",
    "from typing import Sequence\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from ignite.contrib.handlers import ProgressBar, EpochOutputStore\n",
    "from ignite.engine import Events, Engine, DeterministicEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "from model.utils.torch import  set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 16\n",
    "prediction_horizon = 14\n",
    "\n",
    "dataset_path = f\"../data/somof_data_3dpw\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_pose(kpts):\n",
    "    out = (kpts - kpts[..., 0:1, :])[..., 1:, :]\n",
    "    return out\n",
    "\n",
    "class ZeroPoseGTTrajectoryBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroPoseGTTrajectoryBaseline, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor,ph: int = 1)  -> torch.Tensor:\n",
    "        pose_centered = center_pose(x)[..., -1 ,:,:].unsqueeze(-3)\n",
    "        gt_trajectory = y[..., 0:1,:]\n",
    "        out = torch.cat([gt_trajectory, pose_centered+gt_trajectory], dim=-2)\n",
    "        return out\n",
    "        \n",
    "class ZeroBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroBaseline, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, ph: int = 1)  -> torch.Tensor:\n",
    "        last_frame = x[..., -1 ,:,:].unsqueeze(-3)\n",
    "        B, P, T, N, D = last_frame.shape\n",
    "        last_frame.broadcast_to((B, ph, N, D))\n",
    "        return last_frame\n",
    "    \n",
    "class ZeroPoseLastVelocityBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroPoseLastVelocityBaseline, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, ph: int = 1)  -> torch.Tensor:\n",
    "        pose_centered = center_pose(x)[..., -1 ,:,:].unsqueeze(-3)\n",
    "        # last_velocity = (x[..., -3: ,0:1,:] - x[..., -4:-1 ,0:1,:]).mean(-3).unsqueeze(-3) # B, 1, 1, 3 \n",
    "        last_velocity = x[..., -1: ,0:1,:] - x[..., -2:-1 ,0:1,:] # B, 1, 1, 3 \n",
    "        B, P, T, N, D = last_velocity.shape # N = 1\n",
    "        displacement = torch.cat([last_velocity*i for i in range(1, ph+1)], dim=-3) # B, ph, 1, 3 \n",
    "        displacement +=  x[..., -1 ,0:1,:].unsqueeze(-3)\n",
    "        \n",
    "        out = torch.cat([displacement, pose_centered+displacement], dim=-2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoMoFDataset(UserDict):\n",
    "    original_resolution = [1002, 1000]  # from video data\n",
    "    images_subdir = 'ImageSequence'\n",
    "    dataset_name = \"3dpw\" #\"posetrack\" \n",
    "\n",
    "\n",
    "    def __init__(self, dataset_path, \n",
    "                 num_joints=13, **kwargs):\n",
    "\n",
    "        self.datase_path = dataset_path\n",
    "        name_split = \"test\"\n",
    "        dataset_name = \"3dpw\" #\"posetrack\"\n",
    "        assert num_joints == 13\n",
    "        self.num_joints = num_joints\n",
    "        # self.n_keypoints = 13\n",
    "        \n",
    "        super().__init__(self._load(self.datase_path, dataset_name, self.num_joints, name_split))\n",
    "\n",
    "        print(f'Successfully created SoMoF {dataset_name} dataset from file: ', dataset_path,\n",
    "              '\\n\\tnumber of samples: ', len(self[\"poses_3d\"]),\n",
    "                )\n",
    "    def __len__(self):\n",
    "        return len(self[\"poses_3d\"])\n",
    "                \n",
    "    @staticmethod\n",
    "    def _load(dataset_path, dataset_name, num_joints, name_split=\"train\"):\n",
    "        with open(os.path.join(dataset_path, f\"{dataset_name}_{name_split}_in.json\"), 'r') as f:\n",
    "            data_in = np.array(json.load(f)) #(221, 2, 16, 39)\n",
    "    \n",
    "        data_in = torch.from_numpy(data_in).view(data_in.shape[0], data_in.shape[1], data_in.shape[2], \n",
    "                                                 num_joints, 3).float()\n",
    "        data = data_in\n",
    "        # from meters to mm\n",
    "        # data *= 1000\n",
    "        result = {\"poses_3d\": data,\n",
    "                  \"gt\": data}\n",
    "        return result\n",
    "\n",
    "class SoMoFTorchDataset(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 dataset: SoMoFDataset,\n",
    "                 history_length: int,\n",
    "                 prediction_horizon: int,\n",
    "                **kwargs\n",
    "                 ):\n",
    "        \n",
    "        self.history_length = history_length\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        assert history_length == 16\n",
    "        assert prediction_horizon == 14\n",
    "\n",
    "        self._data = dataset\n",
    "        print(\"Len of sample: \", self.__len__())\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        poses = self._data[\"poses_3d\"][item]\n",
    "        return poses\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZeroPoseLastVelocityBaseline() # chose baseline\n",
    "baseline_name = \"ZeroPoseLastVelocityBaseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created SoMoF 3dpw dataset from file:  ../data/somof_data_3dpw \n",
      "\tnumber of samples:  85\n",
      "Len of sample:  85\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "# Init seed\n",
    "device = \"cpu\"\n",
    "set_seed(seed=0)\n",
    "\n",
    "dataset = SoMoFDataset(dataset_path, split=\"valid\", num_joints=13)\n",
    "torch_dataset = SoMoFTorchDataset(dataset=dataset, history_length=history_length,  prediction_horizon=prediction_horizon)\n",
    "data_loader = DataLoader(torch_dataset, shuffle=False, batch_size=50, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(engine: Engine):\n",
    "        engine.state.batch =  engine.state.batch.to(device)\n",
    "def validation_step_eval(engine: Engine, batch: Sequence[torch.Tensor]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = batch\n",
    "        model_out = model(x, ph=prediction_horizon)\n",
    "        return model_out, x\n",
    "\n",
    "\n",
    "evaluator = DeterministicEngine(validation_step_eval)\n",
    "evaluator.add_event_handler(Events.ITERATION_STARTED, preprocess)\n",
    "\n",
    "eos = EpochOutputStore()\n",
    "eos.attach(evaluator, 'output')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.attach(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8908bb1856ac45cda4e57fc88e2ddc48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/2]  50%|#####      [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 2, 14, 39])\n"
     ]
    }
   ],
   "source": [
    "state = evaluator.run(data_loader)\n",
    "output = torch.cat([kpts for kpts, start in state.output], dim=0)\n",
    "output = output.view((-1, 2, 14, 13*3))\n",
    "print(output.shape)\n",
    "os.makedirs(f\"result_baselines/somof/baselines_{baseline_name}\", exist_ok=True)\n",
    "with open(os.path.join(f\"result_baselines/somof/baselines_{baseline_name}\", '3dpw_predictions.json'), 'w') as f:\n",
    "    f.write(json.dumps(output.tolist()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5819f3b8f5800803f3e1de74b59ba921220bb925d6306341dfc4ace99a37b42c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
