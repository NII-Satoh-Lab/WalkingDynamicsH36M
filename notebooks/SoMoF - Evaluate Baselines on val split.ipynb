{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Sequence\n",
    "from collections import UserDict\n",
    "from torch.utils import data\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from ignite.contrib.handlers import ProgressBar, EpochOutputStore\n",
    "from ignite.engine import Events, Engine, DeterministicEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from model.utils.torch import  set_seed\n",
    "from model.core.metrics.mpjpe import MeanPerJointPositionError\n",
    "from model.core.metrics.fde import FinalDisplacementError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 16\n",
    "prediction_horizon = 14\n",
    "\n",
    "dataset_path = f\"../data/somof_data_3dpw\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_pose(output):\n",
    "    out = (output - output[..., 0:1, :])[..., 1:, :]\n",
    "    return out\n",
    "\n",
    "class ZeroPoseGTTrajectoryBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroPoseGTTrajectoryBaseline, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor,ph: int = 1)  -> torch.Tensor:\n",
    "        pose_centered = center_pose(x)[..., -1 ,:,:].unsqueeze(-3)\n",
    "        gt_trajectory = y[..., 0:1,:]\n",
    "        out = torch.cat([gt_trajectory, pose_centered+gt_trajectory], dim=-2)\n",
    "        return out\n",
    "        \n",
    "class ZeroBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroBaseline, self).__init__()\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor,ph: int = 1)  -> torch.Tensor:\n",
    "        last_frame = x[..., -1 ,:,:].unsqueeze(-3)\n",
    "        B, T, N, D = last_frame.shape\n",
    "        last_frame.broadcast_to((B, ph, N, D))\n",
    "        return last_frame\n",
    "    \n",
    "class ZeroPoseLastVelocityBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroPoseLastVelocityBaseline, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor,ph: int = 1)  -> torch.Tensor:\n",
    "        pose_centered = center_pose(x)[..., -1 ,:,:].unsqueeze(-3)\n",
    "        # last_velocity = (x[..., -3: ,0:1,:] - x[..., -4:-1 ,0:1,:]).mean(-3).unsqueeze(-3) # B, 1, 1, 3 \n",
    "        last_velocity = x[..., -1: ,0:1,:] - x[..., -2:-1 ,0:1,:] # B, 1, 1, 3 \n",
    "        B, T, N, D = last_velocity.shape # N = 1\n",
    "        displacement = torch.cat([last_velocity*i for i in range(1, ph+1)], dim=-3) # B, ph, 1, 3 \n",
    "        displacement +=  x[..., -1 ,0:1,:].unsqueeze(-3)\n",
    "        \n",
    "        out = torch.cat([displacement, pose_centered+displacement], dim=-2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoMoFDataset(UserDict):\n",
    "    \"\"\" \"\"\"\n",
    "    original_resolution = [1002, 1000]  # from video data\n",
    "    images_subdir = 'ImageSequence'\n",
    "    dataset_name = \"3dpw\" #\"posetrack\" \n",
    "\n",
    "\n",
    "    def __init__(self, dataset_path, \n",
    "                 num_joints=13, split=\"train\", **kwargs):\n",
    "\n",
    "        self.datase_path = dataset_path\n",
    "        assert split in [\"train\", \"valid\"]\n",
    "        name_split = split\n",
    "        dataset_name = \"3dpw\" #\"posetrack\"\n",
    "        assert num_joints == 13\n",
    "        self.num_joints = num_joints\n",
    "        \n",
    "        # self.n_keypoints = 13\n",
    "        \n",
    "        super().__init__(self._load(self.datase_path, dataset_name, self.num_joints, name_split))\n",
    "\n",
    "        print(f'Successfully created SoMoF {dataset_name} dataset from file: ', dataset_path,\n",
    "              '\\n\\tsplit: ', split,\n",
    "              '\\n\\tnumber of samples: ', len(self[\"poses_3d\"]),\n",
    "            )\n",
    "    def __len__(self):\n",
    "        return len(self[\"poses_3d\"])\n",
    "                \n",
    "    @staticmethod\n",
    "    def _load(dataset_path, dataset_name, num_joints, name_split=\"train\"):\n",
    "        \"\"\"returns a dict with img_paths, poses3d, hip3d, centered3d\n",
    "\n",
    "        Args:\n",
    "            path (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        with open(os.path.join(dataset_path, f\"{dataset_name}_{name_split}_in.json\"), 'r') as f:\n",
    "            data_in = np.array(json.load(f)) #(221, 2, 16, 39)\n",
    "        with open(os.path.join(dataset_path, f\"{dataset_name}_{name_split}_out.json\"), 'r') as f:\n",
    "            data_out = np.array(json.load(f)) #(221, 2, 14, 39)\n",
    "            \n",
    "        data_in = torch.from_numpy(data_in).view(data_in.shape[0]*data_in.shape[1], data_in.shape[2], \n",
    "                                                 num_joints, 3).float()\n",
    "        data_out = torch.from_numpy(data_out).view(data_out.shape[0]*data_out.shape[1], data_out.shape[2], \n",
    "                                                 num_joints, 3).float()\n",
    "        \n",
    "        data = torch.cat([data_in, data_out], dim=-3)\n",
    "        # from meters to mm\n",
    "        data *= 1000\n",
    "        result = {\"poses_3d\": data,\n",
    "                  \"gt\": data}\n",
    "        return result\n",
    "\n",
    "class SoMoFTorchDataset(data.Dataset):\n",
    "    def __init__(self,\n",
    "                 dataset: SoMoFDataset,\n",
    "                 history_length: int,\n",
    "                 prediction_horizon: int,\n",
    "                **kwargs\n",
    "                 ):\n",
    "        \n",
    "        self.history_length = history_length\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "        assert history_length == 16\n",
    "        assert prediction_horizon == 14\n",
    "\n",
    "        self._data = dataset\n",
    "        print(\"Len of sample: \", self.__len__())\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        poses = self._data[\"poses_3d\"][item]\n",
    "        return poses[:self.history_length], poses[self.history_length: self.history_length + self.prediction_horizon]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZeroPoseLastVelocityBaseline() # chose baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created SoMoF 3dpw dataset from file:  ../data/somof_data_3dpw \n",
      "\tsplit:  valid \n",
      "\tnumber of samples:  72\n",
      "Len of sample:  72\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "# Init seed\n",
    "device = \"cpu\"\n",
    "set_seed(seed=0)\n",
    "\n",
    "dataset = SoMoFDataset(dataset_path, split=\"valid\", num_joints=13)\n",
    "torch_dataset = SoMoFTorchDataset(dataset=dataset, history_length=history_length,  prediction_horizon=prediction_horizon)\n",
    "data_loader = DataLoader(torch_dataset, shuffle=False, batch_size=50, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(engine: Engine):\n",
    "        engine.state.batch =  [t.to(device) for t in engine.state.batch[:]]\n",
    "        \n",
    "def validation_step_eval(engine: Engine, batch: Sequence[torch.Tensor]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        model_out = model(x, y, ph=prediction_horizon)\n",
    "        return model_out, y, x\n",
    "\n",
    "def extract_hip(output):\n",
    "    output = [out[...,0:1,:] for out in output[:2]]\n",
    "    return output[0], output[1]\n",
    "\n",
    "def extract_pose(output):\n",
    "    output = [(out - out[..., 0:1, :])[..., 1:, :] for out in output[:2]]\n",
    "    return output[0], output[1]\n",
    "\n",
    "# Define ignite metrics\n",
    "mpjpe = MeanPerJointPositionError()\n",
    "mpjpe_pose = MeanPerJointPositionError(output_transform=extract_pose)\n",
    "mpjpe_avg = MeanPerJointPositionError(keep_time_dim=False)\n",
    "mpjpe_hip = MeanPerJointPositionError(output_transform=extract_hip, keep_time_dim=True)\n",
    "\n",
    "fde = FinalDisplacementError()\n",
    "fde_pose = FinalDisplacementError(output_transform=extract_pose)\n",
    "fde_hip = FinalDisplacementError(output_transform=extract_hip)\n",
    "\n",
    "evaluator = DeterministicEngine(validation_step_eval)\n",
    "evaluator.add_event_handler(Events.ITERATION_STARTED, preprocess)\n",
    "mpjpe.attach(evaluator, 'MPJPE')\n",
    "mpjpe_pose.attach(evaluator, 'MPJPE_POSE')\n",
    "mpjpe_avg.attach(evaluator, 'MPJPE_AVG')\n",
    "mpjpe_hip.attach(evaluator, 'MPJPE_HIP')\n",
    "fde.attach(evaluator, 'FDE')\n",
    "fde_pose.attach(evaluator, 'FDE_POSE')\n",
    "fde_hip.attach(evaluator, 'FDE_HIP')\n",
    "\n",
    "eos = EpochOutputStore()\n",
    "eos.attach(evaluator, 'output')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.attach(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab73e68445d43fa98bdd2d7ce0cb50f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/2]  50%|#####      [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on eval val in cm:  {'MPJPE table': [3.5, 7.3, 14.6, 18.1, 25.5], 'MPJPE avg': 13.6, 'MPJPE POSE table': [3.5, 6.5, 10.7, 11.9, 13.6], 'MPJPE POSE avg': 9.3, 'MPJPE HIP table': [1.2, 3.5, 9.8, 13.0, 19.9], 'MPJPE HIP avg': 9.3, 'FDE': 25.5, 'FDE_POSE': 13.6, 'FDE_HIP': 19.9}\n"
     ]
    }
   ],
   "source": [
    "state = evaluator.run(data_loader)\n",
    "metrics = {}\n",
    "metrics[\"MPJPE table\"] = [round((state.metrics[\"MPJPE\"][i]/10).item(), 1) for i in [1,3,7,9,13]]\n",
    "metrics[\"MPJPE avg\"] = round(state.metrics[\"MPJPE\"].mean().item()/10, 1)\n",
    "metrics[\"MPJPE POSE table\"] = [round((state.metrics[\"MPJPE_POSE\"][i]).item()/10, 1) for i in [1,3,7,9,13]]\n",
    "metrics[\"MPJPE POSE avg\"] = round(state.metrics[\"MPJPE_POSE\"].mean().item()/10, 1)\n",
    "metrics[\"MPJPE HIP table\"] = [round((state.metrics[\"MPJPE_HIP\"][i]).item()/10, 1) for i in [1,3,7,9,13]]\n",
    "metrics[\"MPJPE HIP avg\"] = round(state.metrics[\"MPJPE_HIP\"].mean().item()/10, 1)\n",
    "for m,v in state.metrics.items():\n",
    "    if \"FDE\" in m:\n",
    "        metrics[m] = round(v/10, 1)\n",
    "    \n",
    "\n",
    "print(f\"Result on eval val in cm: \", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5819f3b8f5800803f3e1de74b59ba921220bb925d6306341dfc4ace99a37b42c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
