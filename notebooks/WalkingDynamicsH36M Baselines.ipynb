{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from typing import Sequence\n",
    "from collections import UserDict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from ignite.contrib.handlers import ProgressBar, EpochOutputStore\n",
    "from ignite.engine import Events, Engine, DeterministicEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from model.utils.torch import  set_seed\n",
    "from model.core.metrics.mpjpe import MeanPerJointPositionError\n",
    "from model.core.metrics.fde import FinalDisplacementError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_length = 50\n",
    "prediction_horizon = 100\n",
    "\n",
    "dataset_path = f\"../data/WalkingDynamicsH36M_history_{history_length}_pred_horiz_{prediction_horizon}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_pose(output):\n",
    "    out = (output - output[..., 0:1, :])[..., 1:, :]\n",
    "    return out\n",
    "\n",
    "class ZeroPoseGTTrajectoryBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroPoseGTTrajectoryBaseline, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor,ph: int = 1)  -> torch.Tensor:\n",
    "        pose_centered = center_pose(x)[..., -1 ,:,:].unsqueeze(-3)\n",
    "        gt_trajectory = y[..., 0:1,:]\n",
    "        out = torch.cat([gt_trajectory, pose_centered+gt_trajectory], dim=-2)\n",
    "        return out\n",
    "        \n",
    "class ZeroBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroBaseline, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor,ph: int = 1)  -> torch.Tensor:\n",
    "        last_frame = x[..., -1 ,:,:].unsqueeze(-3)\n",
    "        B, T, N, D = last_frame.shape\n",
    "        last_frame.broadcast_to((B, ph, N, D))\n",
    "        return last_frame\n",
    "    \n",
    "class ZeroPoseLastVelocityBaseline(torch.nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ZeroPoseLastVelocityBaseline, self).__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor,ph: int = 1)  -> torch.Tensor:\n",
    "        pose_centered = center_pose(x)[..., -1 ,:,:].unsqueeze(-3)\n",
    "        # last_velocity = (x[..., -3: ,0:1,:] - x[..., -4:-1 ,0:1,:]).mean(-3).unsqueeze(-3) # B, 1, 1, 3 # holds worse results\n",
    "        last_velocity = x[..., -1: ,0:1,:] - x[..., -2:-1 ,0:1,:] # B, 1, 1, 3 \n",
    "        B, T, N, D = last_velocity.shape # N = 1\n",
    "        displacement = torch.cat([last_velocity*i for i in range(1, ph+1)], dim=-3) # B, ph, 1, 3 \n",
    "        displacement +=  x[..., -1 ,0:1,:].unsqueeze(-3)\n",
    "        \n",
    "        out = torch.cat([displacement, pose_centered+displacement], dim=-2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H36MValDataset(UserDict):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_val_path, split=\"val\",\n",
    "                 num_joints=25, **kwargs):\n",
    "\n",
    "        self.datase_file_path = dataset_val_path\n",
    "        self.subjects = ...\n",
    "        self.n_keypoints = num_joints\n",
    "        assert self.n_keypoints in [32, 25, 17]  \n",
    "        assert split in [\"val\", \"test\"]\n",
    "        \n",
    "        super().__init__(self._load(self.datase_file_path, split, num_joints))\n",
    "\n",
    "        print(f'Successfully created H36M dataset',\n",
    "              '\\n\\tsplit: val my dataset',\n",
    "              '\\n\\tnumber of sequences: ', len(self[\"poses_3d\"]),\n",
    "              )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self[\"poses_3d\"])\n",
    "                \n",
    "    @staticmethod\n",
    "    def _load(dataset_path, split, n_kpts):      \n",
    "        with open(os.path.join(dataset_path, f\"{split}_poses.json\"), 'r') as f:\n",
    "            data = np.array(json.load(f)) #(221, 2, 16, 39)\n",
    "        with open(os.path.join(dataset_path, f\"{split}_images.json\"), 'r') as f:\n",
    "            frames = np.array(json.load(f)) #(221, 16)\n",
    "        seqs = [fs[0].split(\"img\")[0][:-1] for fs in frames]\n",
    "        assert n_kpts == data.shape[-2]\n",
    "        kpts = torch.from_numpy(data).float()\n",
    "        result = {  \"poses_3d\": kpts,\n",
    "            \"img_paths\": frames,\n",
    "            \"seq_names\": seqs}\n",
    "        return result\n",
    "    \n",
    "class WalDynH36MTorchValDataset():\n",
    "    def __init__(self, dataset: H36MValDataset, history_length: int,  prediction_horizon: int):\n",
    "        self.history_length = history_length\n",
    "        self.prediction_horizon = prediction_horizon\n",
    "    \n",
    "        self.action = \"Custom\"\n",
    "\n",
    "        self._data = dataset\n",
    "        print(f'Successfully created H36M dataloder',\n",
    "              '\\n\\taction: ', self.action,\n",
    "              '\\n\\tnumber of samples: ', self.__len__(),\n",
    "              )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._data[\"poses_3d\"])\n",
    "        \n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data = self._data[\"poses_3d\"][item]\n",
    "        return data[:self.history_length], data[self.history_length: self.history_length + self.prediction_horizon]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ZeroPoseLastVelocityBaseline() # chose baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created H36M dataset \n",
      "\tsplit: val my dataset \n",
      "\tnumber of sequences:  32\n",
      "Successfully created H36M dataloder \n",
      "\taction:  Custom \n",
      "\tnumber of samples:  32\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "# Init seed\n",
    "device = \"cpu\"\n",
    "set_seed(seed=0)\n",
    "\n",
    "dataset = H36MValDataset(dataset_path, split=\"test\")\n",
    "torch_dataset = WalDynH36MTorchValDataset(dataset=dataset, history_length=history_length,  prediction_horizon=prediction_horizon)\n",
    "data_loader = DataLoader(torch_dataset, shuffle=False, batch_size=50, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(engine: Engine):\n",
    "        engine.state.batch =  [t.to(device) for t in engine.state.batch[:]]\n",
    "        \n",
    "def validation_step_eval(engine: Engine, batch: Sequence[torch.Tensor]):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y = batch\n",
    "        model_out = model(x, y, ph=prediction_horizon)\n",
    "        return model_out, y, x\n",
    "\n",
    "def extract_hip(output):\n",
    "    output = [out[...,0:1,:] for out in output[:2]]\n",
    "    return output[0], output[1]\n",
    "\n",
    "def extract_pose(output):\n",
    "    output = [(out - out[..., 0:1, :])[..., 1:, :] for out in output[:2]]\n",
    "    return output[0], output[1]\n",
    "\n",
    "# Define ignite metrics\n",
    "mpjpe = MeanPerJointPositionError()\n",
    "mpjpe_pose = MeanPerJointPositionError(output_transform=extract_pose)\n",
    "mpjpe_avg = MeanPerJointPositionError(keep_time_dim=False)\n",
    "mpjpe_hip = MeanPerJointPositionError(output_transform=extract_hip, keep_time_dim=True)\n",
    "\n",
    "fde = FinalDisplacementError()\n",
    "fde_pose = FinalDisplacementError(output_transform=extract_pose)\n",
    "fde_hip = FinalDisplacementError(output_transform=extract_hip)\n",
    "\n",
    "evaluator = DeterministicEngine(validation_step_eval)\n",
    "evaluator.add_event_handler(Events.ITERATION_STARTED, preprocess)\n",
    "mpjpe.attach(evaluator, 'MPJPE')\n",
    "mpjpe_pose.attach(evaluator, 'MPJPE_POSE')\n",
    "mpjpe_avg.attach(evaluator, 'MPJPE_AVG')\n",
    "mpjpe_hip.attach(evaluator, 'MPJPE_HIP')\n",
    "fde.attach(evaluator, 'FDE')\n",
    "fde_pose.attach(evaluator, 'FDE_POSE')\n",
    "fde_hip.attach(evaluator, 'FDE_HIP')\n",
    "\n",
    "eos = EpochOutputStore()\n",
    "eos.attach(evaluator, 'output')\n",
    "\n",
    "pbar = ProgressBar()\n",
    "pbar.attach(evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6223f2900fc46b79ddc8b2599f62adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1] 100%|########## [00:00<?]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result on eval val:  {'MPJPE table': [36.4, 355.2, 810.6, 1477.8, 2262.6], 'MPJPE avg': 947.7, 'MPJPE POSE table': [37.3, 206.6, 250.1, 286.4, 344.2], 'MPJPE POSE avg': 240.0, 'MPJPE HIP table': [7.7, 276.9, 740.6, 1400.4, 2180.4], 'MPJPE HIP avg': 874.0, 'FDE': 2262.6, 'FDE_POSE': 344.2, 'FDE_HIP': 2180.4}\n"
     ]
    }
   ],
   "source": [
    "state = evaluator.run(data_loader)\n",
    "metrics = {}\n",
    "metrics[\"MPJPE table\"] = [round((state.metrics[\"MPJPE\"][i]).item(), 1) for i in [1, 24, 49, 74, -1]]\n",
    "metrics[\"MPJPE avg\"] = round(state.metrics[\"MPJPE\"].mean().item(), 1)\n",
    "metrics[\"MPJPE POSE table\"] = [round((state.metrics[\"MPJPE_POSE\"][i]).item(), 1) for i in [1, 24, 49, 74, -1]]\n",
    "metrics[\"MPJPE POSE avg\"] = round(state.metrics[\"MPJPE_POSE\"].mean().item(), 1)\n",
    "metrics[\"MPJPE HIP table\"] = [round((state.metrics[\"MPJPE_HIP\"][i]).item(), 1) for i in [1, 24, 49, 74, -1]]\n",
    "metrics[\"MPJPE HIP avg\"] = round(state.metrics[\"MPJPE_HIP\"].mean().item(), 1)\n",
    "for m,v in state.metrics.items():\n",
    "    if \"FDE\" in m:\n",
    "        metrics[m] = round(v, 1)\n",
    "    \n",
    "\n",
    "print(f\"Result on eval val: \", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5819f3b8f5800803f3e1de74b59ba921220bb925d6306341dfc4ace99a37b42c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
